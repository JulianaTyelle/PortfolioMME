{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: chromedriver-autoinstaller in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\juliana.pires\\appdata\\roaming\\python\\python312\\site-packages (from chromedriver-autoinstaller) (24.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\juliana.pires\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juliana.pires\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: bs4 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install chromedriver-autoinstaller\n",
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service()\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://anmlegis.datalegis.net/action/ActionDatalegis.php?acao=apresentacao&cod_modulo=351&cod_menu=8014\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/a[4]').click()\n",
    "#clica em \"TÃ­tulos Outorgados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div/div[2]/div[4]/ul/li[1]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"Alvara de Pesquisa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[1]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2024 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2024 in range (125):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2024 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2024 == last_height2024 :\n",
    "        break   \n",
    "    last_height2024 = new_height2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2024 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2024 = soup2024.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2024 = tabela2024.find_all('strong', {})\n",
    "conteudos2024 = tabela2024.find_all('p')[0:5500:2]\n",
    "datasPublicacao2024 = tabela2024.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2024 = []\n",
    "lista_conteudos2024 = []\n",
    "lista_datasPublicacao2024 = []\n",
    "\n",
    "for titulo2024 in titulos2024:\n",
    "  lista_titulos2024.append(titulo2024.get_text().strip())\n",
    "\n",
    "for conteudo2024 in conteudos2024:\n",
    "  lista_conteudos2024.append(conteudo2024.get_text().strip())\n",
    "\n",
    "for dataPublicacao2024 in datasPublicacao2024:\n",
    "  lista_datasPublicacao2024.append(dataPublicacao2024.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2024 = pd.DataFrame([lista_titulos2024, lista_conteudos2024, lista_datasPublicacao2024]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[2]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2023 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2023 in range (700):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2023 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2023 == last_height2023 :\n",
    "        break   \n",
    "    last_height2023 = new_height2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2023 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2023 = soup2023.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2023 = tabela2023.find_all('strong', {})\n",
    "conteudos2023 = tabela2023.find_all('p')[0:28000:2]\n",
    "datasPublicacao2023 = tabela2023.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2023 = []\n",
    "lista_conteudos2023 = []\n",
    "lista_datasPublicacao2023 = []\n",
    "\n",
    "for titulo2023 in titulos2023:\n",
    "  lista_titulos2023.append(titulo2023.get_text().strip())\n",
    "\n",
    "for conteudo2023 in conteudos2023:\n",
    "  lista_conteudos2023.append(conteudo2023.get_text().strip())\n",
    "\n",
    "for dataPublicacao2023 in datasPublicacao2023:\n",
    "  lista_datasPublicacao2023.append(dataPublicacao2023.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2023 = pd.DataFrame([lista_titulos2023, lista_conteudos2023, lista_datasPublicacao2023]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[3]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2022 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2022 in range (600):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2022 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2022 == last_height2022 :\n",
    "        break   \n",
    "    last_height2022 = new_height2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2022 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2022 = soup2022.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2022 = tabela2022.find_all('strong', {})\n",
    "conteudos2022 = tabela2022.find_all('p')[0:24000:2]\n",
    "datasPublicacao2022 = tabela2022.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2022 = []\n",
    "lista_conteudos2022 = []\n",
    "lista_datasPublicacao2022 = []\n",
    "\n",
    "for titulo2022 in titulos2022:\n",
    "  lista_titulos2022.append(titulo2022.get_text().strip())\n",
    "\n",
    "for conteudo2022 in conteudos2022:\n",
    "  lista_conteudos2022.append(conteudo2022.get_text().strip())\n",
    "\n",
    "for dataPublicacao2022 in datasPublicacao2022:\n",
    "  lista_datasPublicacao2022.append(dataPublicacao2022.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2022 = pd.DataFrame([lista_titulos2022, lista_conteudos2022, lista_datasPublicacao2022]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[4]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2021 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2021 in range (600):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2021 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2021 == last_height2021 :\n",
    "        break   \n",
    "    last_height2021 = new_height2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2021 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2021 = soup2021.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2021 = tabela2021.find_all('strong', {})\n",
    "conteudos2021 = tabela2021.find_all('p')[0:24000:2]\n",
    "datasPublicacao2021 = tabela2021.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2021 = []\n",
    "lista_conteudos2021 = []\n",
    "lista_datasPublicacao2021 = []\n",
    "\n",
    "for titulo2021 in titulos2021:\n",
    "  lista_titulos2021.append(titulo2021.get_text().strip())\n",
    "\n",
    "for conteudo2021 in conteudos2021:\n",
    "  lista_conteudos2021.append(conteudo2021.get_text().strip())\n",
    "\n",
    "for dataPublicacao2021 in datasPublicacao2021:\n",
    "  lista_datasPublicacao2021.append(dataPublicacao2021.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2021 = pd.DataFrame([lista_titulos2021, lista_conteudos2021, lista_datasPublicacao2021]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[5]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2020 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2020 in range (300):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2020 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2020 == last_height2020 :\n",
    "        break   \n",
    "    last_height2020 = new_height2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2020 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2020 = soup2020.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2020 = tabela2020.find_all('strong', {})\n",
    "conteudos2020 = tabela2020.find_all('p')[0:12000:2]\n",
    "datasPublicacao2020 = tabela2020.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2020 = []\n",
    "lista_conteudos2020 = []\n",
    "lista_datasPublicacao2020 = []\n",
    "\n",
    "for titulo2020 in titulos2020:\n",
    "  lista_titulos2020.append(titulo2020.get_text().strip())\n",
    "\n",
    "for conteudo2020 in conteudos2020:\n",
    "  lista_conteudos2020.append(conteudo2020.get_text().strip())\n",
    "\n",
    "for dataPublicacao2020 in datasPublicacao2020:\n",
    "  lista_datasPublicacao2020.append(dataPublicacao2020.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2020 = pd.DataFrame([lista_titulos2020, lista_conteudos2020, lista_datasPublicacao2020]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[6]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2019 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2019 in range (400):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2019 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2019 == last_height2019 :\n",
    "        break   \n",
    "    last_height2019 = new_height2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2019 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2019 = soup2019.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2019 = tabela2019.find_all('strong', {})\n",
    "conteudos2019 = tabela2019.find_all('p')[0:5500:2]\n",
    "datasPublicacao2019 = tabela2019.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2019 = []\n",
    "lista_conteudos2019 = []\n",
    "lista_datasPublicacao2019 = []\n",
    "\n",
    "for titulo2019 in titulos2019:\n",
    "  lista_titulos2019.append(titulo2019.get_text().strip())\n",
    "\n",
    "for conteudo2019 in conteudos2019:\n",
    "  lista_conteudos2019.append(conteudo2019.get_text().strip())\n",
    "\n",
    "for dataPublicacao2019 in datasPublicacao2019:\n",
    "  lista_datasPublicacao2019.append(dataPublicacao2019.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2019 = pd.DataFrame([lista_titulos2019, lista_conteudos2019, lista_datasPublicacao2019]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[7]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2018 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2018 in range (400):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2018 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2018 == last_height2018 :\n",
    "        break   \n",
    "    last_height2018 = new_height2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2018 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2018 = soup2018.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2018 = tabela2018.find_all('strong', {})\n",
    "conteudos2018 = tabela2018.find_all('p')[0:16000:2]\n",
    "datasPublicacao2018 = tabela2018.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2018 = []\n",
    "lista_conteudos2018 = []\n",
    "lista_datasPublicacao2018 = []\n",
    "\n",
    "for titulo2018 in titulos2018:\n",
    "  lista_titulos2018.append(titulo2018.get_text().strip())\n",
    "\n",
    "for conteudo2018 in conteudos2018:\n",
    "  lista_conteudos2018.append(conteudo2018.get_text().strip())\n",
    "\n",
    "for dataPublicacao2018 in datasPublicacao2018:\n",
    "  lista_datasPublicacao2018.append(dataPublicacao2018.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2018 = pd.DataFrame([lista_titulos2018, lista_conteudos2018, lista_datasPublicacao2018]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[8]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2017 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2017 in range (550):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2017 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2017 == last_height2017 :\n",
    "        break   \n",
    "    last_height2017 = new_height2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2017 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2017 = soup2017.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2017 = tabela2017.find_all('strong', {})\n",
    "conteudos2017 = tabela2017.find_all('p')[0:22000:2]\n",
    "datasPublicacao2017 = tabela2017.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2017 = []\n",
    "lista_conteudos2017 = []\n",
    "lista_datasPublicacao2017 = []\n",
    "\n",
    "for titulo2017 in titulos2017:\n",
    "  lista_titulos2017.append(titulo2017.get_text().strip())\n",
    "\n",
    "for conteudo2017 in conteudos2017:\n",
    "  lista_conteudos2017.append(conteudo2017.get_text().strip())\n",
    "\n",
    "for dataPublicacao2017 in datasPublicacao2017:\n",
    "  lista_datasPublicacao2017.append(dataPublicacao2017.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2017 = pd.DataFrame([lista_titulos2017, lista_conteudos2017, lista_datasPublicacao2017]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[9]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2016 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2016 in range (400):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2016 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2016 == last_height2016 :\n",
    "        break   \n",
    "    last_height2016 = new_height2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2016 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2016 = soup2016.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2016 = tabela2016.find_all('strong', {})\n",
    "conteudos2016 = tabela2016.find_all('p')[0:16000:2]\n",
    "datasPublicacao2016 = tabela2016.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2016 = []\n",
    "lista_conteudos2016 = []\n",
    "lista_datasPublicacao2016 = []\n",
    "\n",
    "for titulo2016 in titulos2016:\n",
    "  lista_titulos2016.append(titulo2016.get_text().strip())\n",
    "\n",
    "for conteudo2016 in conteudos2016:\n",
    "  lista_conteudos2016.append(conteudo2016.get_text().strip())\n",
    "\n",
    "for dataPublicacao2016 in datasPublicacao2016:\n",
    "  lista_datasPublicacao2016.append(dataPublicacao2016.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2016 = pd.DataFrame([lista_titulos2016, lista_conteudos2016, lista_datasPublicacao2016]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[10]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2015 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2015 in range (1000):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2015 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2015 == last_height2015 :\n",
    "        break   \n",
    "    last_height2015 = new_height2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2015 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2015 = soup2015.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2015 = tabela2015.find_all('strong', {})\n",
    "conteudos2015 = tabela2015.find_all('p')[0:40000:2]\n",
    "datasPublicacao2015 = tabela2015.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2015 = []\n",
    "lista_conteudos2015 = []\n",
    "lista_datasPublicacao2015 = []\n",
    "\n",
    "for titulo2015 in titulos2015:\n",
    "  lista_titulos2015.append(titulo2015.get_text().strip())\n",
    "\n",
    "for conteudo2015 in conteudos2015:\n",
    "  lista_conteudos2015.append(conteudo2015.get_text().strip())\n",
    "\n",
    "for dataPublicacao2015 in datasPublicacao2015:\n",
    "  lista_datasPublicacao2015.append(dataPublicacao2015.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2015 = pd.DataFrame([lista_titulos2015, lista_conteudos2015, lista_datasPublicacao2015]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[11]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2014 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2014 in range (500):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2014 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2014 == last_height2014 :\n",
    "        break   \n",
    "    last_height2014 = new_height2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2014 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2014 = soup2014.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2014 = tabela2014.find_all('strong', {})\n",
    "conteudos2014 = tabela2014.find_all('p')[0:20000:2]\n",
    "datasPublicacao2014 = tabela2014.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2014 = []\n",
    "lista_conteudos2014 = []\n",
    "lista_datasPublicacao2014 = []\n",
    "\n",
    "for titulo2014 in titulos2014:\n",
    "  lista_titulos2014.append(titulo2014.get_text().strip())\n",
    "\n",
    "for conteudo2014 in conteudos2014:\n",
    "  lista_conteudos2014.append(conteudo2014.get_text().strip())\n",
    "\n",
    "for dataPublicacao2014 in datasPublicacao2014:\n",
    "  lista_datasPublicacao2014.append(dataPublicacao2014.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2014 = pd.DataFrame([lista_titulos2014, lista_conteudos2014, lista_datasPublicacao2014]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[12]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2013 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2013 in range (500):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2013 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2013 == last_height2013 :\n",
    "        break   \n",
    "    last_height2013 = new_height2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2013 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2013 = soup2013.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2013 = tabela2013.find_all('strong', {})\n",
    "conteudos2013 = tabela2013.find_all('p')[0:20000:2]\n",
    "datasPublicacao2013 = tabela2013.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2013 = []\n",
    "lista_conteudos2013 = []\n",
    "lista_datasPublicacao2013 = []\n",
    "\n",
    "for titulo2013 in titulos2013:\n",
    "  lista_titulos2013.append(titulo2013.get_text().strip())\n",
    "\n",
    "for conteudo2013 in conteudos2013:\n",
    "  lista_conteudos2013.append(conteudo2013.get_text().strip())\n",
    "\n",
    "for dataPublicacao2013 in datasPublicacao2013:\n",
    "  lista_datasPublicacao2013.append(dataPublicacao2013.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2013 = pd.DataFrame([lista_titulos2013, lista_conteudos2013, lista_datasPublicacao2013]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[1]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2012\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2012 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2012 in range (39):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2012 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2012 == last_height2012 :\n",
    "        break   \n",
    "    last_height2012 = new_height2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2012 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2012 = soup2012.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2012 = tabela2012.find_all('strong', {})\n",
    "conteudos2012 = tabela2012.find_all('p')[0:1600:2]\n",
    "datasPublicacao2012 = tabela2012.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2012 = []\n",
    "lista_conteudos2012 = []\n",
    "lista_datasPublicacao2012 = []\n",
    "\n",
    "for titulo2012 in titulos2012:\n",
    "  lista_titulos2012.append(titulo2012.get_text().strip())\n",
    "\n",
    "for conteudo2012 in conteudos2012:\n",
    "  lista_conteudos2012.append(conteudo2012.get_text().strip())\n",
    "\n",
    "for dataPublicacao2012 in datasPublicacao2012:\n",
    "  lista_datasPublicacao2012.append(dataPublicacao2012.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2012 = pd.DataFrame([lista_titulos2012, lista_conteudos2012, lista_datasPublicacao2012]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[2]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2011 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2011 in range (29):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2011 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2011 == last_height2011 :\n",
    "        break   \n",
    "    last_height2011 = new_height2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2011 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2011 = soup2011.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2011 = tabela2011.find_all('strong', {})\n",
    "conteudos2011 = tabela2011.find_all('p')[0:1200:2]\n",
    "datasPublicacao2011 = tabela2011.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2011 = []\n",
    "lista_conteudos2011 = []\n",
    "lista_datasPublicacao2011 = []\n",
    "\n",
    "for titulo2011 in titulos2011:\n",
    "  lista_titulos2011.append(titulo2011.get_text().strip())\n",
    "\n",
    "for conteudo2011 in conteudos2011:\n",
    "  lista_conteudos2011.append(conteudo2011.get_text().strip())\n",
    "\n",
    "for dataPublicacao2011 in datasPublicacao2011:\n",
    "  lista_datasPublicacao2011.append(dataPublicacao2011.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2011 = pd.DataFrame([lista_titulos2011, lista_conteudos2011, lista_datasPublicacao2011]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[3]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2010 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2010 in range (4):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2010 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2010 == last_height2010 :\n",
    "        break   \n",
    "    last_height2010 = new_height2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2010 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2010 = soup2010.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2010 = tabela2010.find_all('strong', {})\n",
    "conteudos2010 = tabela2010.find_all('p')[0:200:2]\n",
    "datasPublicacao2010 = tabela2010.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2010 = []\n",
    "lista_conteudos2010 = []\n",
    "lista_datasPublicacao2010 = []\n",
    "\n",
    "for titulo2010 in titulos2010:\n",
    "  lista_titulos2010.append(titulo2010.get_text().strip())\n",
    "\n",
    "for conteudo2010 in conteudos2010:\n",
    "  lista_conteudos2010.append(conteudo2010.get_text().strip())\n",
    "\n",
    "for dataPublicacao2010 in datasPublicacao2010:\n",
    "  lista_datasPublicacao2010.append(dataPublicacao2010.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2010 = pd.DataFrame([lista_titulos2010, lista_conteudos2010, lista_datasPublicacao2010]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[4]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2009\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2009 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2009 in range (24):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2009 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2009 == last_height2009 :\n",
    "        break   \n",
    "    last_height2009 = new_height2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2009 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2009 = soup2009.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2009 = tabela2009.find_all('strong', {})\n",
    "conteudos2009 = tabela2009.find_all('p')[0:1000:2]\n",
    "datasPublicacao2009 = tabela2009.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2009 = []\n",
    "lista_conteudos2009 = []\n",
    "lista_datasPublicacao2009 = []\n",
    "\n",
    "for titulo2009 in titulos2009:\n",
    "  lista_titulos2009.append(titulo2009.get_text().strip())\n",
    "\n",
    "for conteudo2009 in conteudos2009:\n",
    "  lista_conteudos2009.append(conteudo2009.get_text().strip())\n",
    "\n",
    "for dataPublicacao2009 in datasPublicacao2009:\n",
    "  lista_datasPublicacao2009.append(dataPublicacao2009.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2009 = pd.DataFrame([lista_titulos2009, lista_conteudos2009, lista_datasPublicacao2009]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[5]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2008\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2008 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2008 in range (12):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2008 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2008 == last_height2008 :\n",
    "        break   \n",
    "    last_height2008 = new_height2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2008 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2008 = soup2008.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2008 = tabela2008.find_all('strong', {})\n",
    "conteudos2008 = tabela2008.find_all('p')[0:500:2]\n",
    "datasPublicacao2008 = tabela2008.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2008 = []\n",
    "lista_conteudos2008 = []\n",
    "lista_datasPublicacao2008 = []\n",
    "\n",
    "for titulo2008 in titulos2008:\n",
    "  lista_titulos2008.append(titulo2008.get_text().strip())\n",
    "\n",
    "for conteudo2008 in conteudos2008:\n",
    "  lista_conteudos2008.append(conteudo2008.get_text().strip())\n",
    "\n",
    "for dataPublicacao2008 in datasPublicacao2008:\n",
    "  lista_datasPublicacao2008.append(dataPublicacao2008.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2008 = pd.DataFrame([lista_titulos2008, lista_conteudos2008, lista_datasPublicacao2008]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[6]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2005 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2005 = soup2005.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2005 = tabela2005.find_all('strong', {})\n",
    "conteudos2005 = tabela2005.find_all('p')[0:6:2]\n",
    "datasPublicacao2005 = tabela2005.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2005 = []\n",
    "lista_conteudos2005 = []\n",
    "lista_datasPublicacao2005 = []\n",
    "\n",
    "for titulo2005 in titulos2005:\n",
    "  lista_titulos2005.append(titulo2005.get_text().strip())\n",
    "\n",
    "for conteudo2005 in conteudos2005:\n",
    "  lista_conteudos2005.append(conteudo2005.get_text().strip())\n",
    "\n",
    "for dataPublicacao2005 in datasPublicacao2005:\n",
    "  lista_datasPublicacao2005.append(dataPublicacao2005.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2005 = pd.DataFrame([lista_titulos2005, lista_conteudos2005, lista_datasPublicacao2005]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[7]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2002 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2002 = soup2002.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2002 = tabela2002.find_all('strong', {})\n",
    "conteudos2002 = tabela2002.find_all('p')[0:10:2]\n",
    "datasPublicacao2002 = tabela2002.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2002 = []\n",
    "lista_conteudos2002 = []\n",
    "lista_datasPublicacao2002 = []\n",
    "\n",
    "for titulo2002 in titulos2002:\n",
    "  lista_titulos2002.append(titulo2002.get_text().strip())\n",
    "\n",
    "for conteudo2002 in conteudos2002:\n",
    "  lista_conteudos2002.append(conteudo2002.get_text().strip())\n",
    "\n",
    "for dataPublicacao2002 in datasPublicacao2002:\n",
    "  lista_datasPublicacao2002.append(dataPublicacao2002.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2002 = pd.DataFrame([lista_titulos2002, lista_conteudos2002, lista_datasPublicacao2002]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[8]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2001 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2001 = soup2001.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2001 = tabela2001.find_all('strong', {})\n",
    "conteudos2001 = tabela2001.find_all('p')[0:6:2]\n",
    "datasPublicacao2001 = tabela2001.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2001 = []\n",
    "lista_conteudos2001 = []\n",
    "lista_datasPublicacao2001 = []\n",
    "\n",
    "for titulo2001 in titulos2001:\n",
    "  lista_titulos2001.append(titulo2001.get_text().strip())\n",
    "\n",
    "for conteudo2001 in conteudos2001:\n",
    "  lista_conteudos2001.append(conteudo2001.get_text().strip())\n",
    "\n",
    "for dataPublicacao2001 in datasPublicacao2001:\n",
    "  lista_datasPublicacao2001.append(dataPublicacao2001.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2001 = pd.DataFrame([lista_titulos2001, lista_conteudos2001, lista_datasPublicacao2001]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[9]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2000 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2000 = soup2000.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2000 = tabela2000.find_all('strong', {})\n",
    "conteudos2000 = tabela2000.find_all('p')[0:10:2]\n",
    "datasPublicacao2000 = tabela2000.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2000 = []\n",
    "lista_conteudos2000 = []\n",
    "lista_datasPublicacao2000 = []\n",
    "\n",
    "for titulo2000 in titulos2000:\n",
    "  lista_titulos2000.append(titulo2000.get_text().strip())\n",
    "\n",
    "for conteudo2000 in conteudos2000:\n",
    "  lista_conteudos2000.append(conteudo2000.get_text().strip())\n",
    "\n",
    "for dataPublicacao2000 in datasPublicacao2000:\n",
    "  lista_datasPublicacao2000.append(dataPublicacao2000.get_text().strip())\n",
    "\n",
    "alvaraPesquisa2000 = pd.DataFrame([lista_titulos2000, lista_conteudos2000, lista_datasPublicacao2000]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[10]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"1992\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1992 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1992 = soup1992.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos1992 = tabela1992.find_all('strong', {})\n",
    "conteudos1992 = tabela1992.find_all('p')[0:6:2]\n",
    "datasPublicacao1992 = tabela1992.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos1992 = []\n",
    "lista_conteudos1992 = []\n",
    "lista_datasPublicacao1992 = []\n",
    "\n",
    "for titulo1992 in titulos1992:\n",
    "  lista_titulos1992.append(titulo1992.get_text().strip())\n",
    "\n",
    "for conteudo1992 in conteudos1992:\n",
    "  lista_conteudos1992.append(conteudo1992.get_text().strip())\n",
    "\n",
    "for dataPublicacao1992 in datasPublicacao1992:\n",
    "  lista_datasPublicacao1992.append(dataPublicacao1992.get_text().strip())\n",
    "\n",
    "alvaraPesquisa1992 = pd.DataFrame([lista_titulos1992, lista_conteudos1992, lista_datasPublicacao1992]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[11]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"1985\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1985 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1985 = soup1985.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos1985 = tabela1985.find_all('strong', {})\n",
    "conteudos1985 = tabela1985.find_all('p')[0:6:2]\n",
    "datasPublicacao1985 = tabela1985.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos1985 = []\n",
    "lista_conteudos1985 = []\n",
    "lista_datasPublicacao1985 = []\n",
    "\n",
    "for titulo1985 in titulos1985:\n",
    "  lista_titulos1985.append(titulo1985.get_text().strip())\n",
    "\n",
    "for conteudo1985 in conteudos1985:\n",
    "  lista_conteudos1985.append(conteudo1985.get_text().strip())\n",
    "\n",
    "for dataPublicacao1985 in datasPublicacao1985:\n",
    "  lista_datasPublicacao1985.append(dataPublicacao1985.get_text().strip())\n",
    "\n",
    "alvaraPesquisa1985 = pd.DataFrame([lista_titulos1985, lista_conteudos1985, lista_datasPublicacao1985]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvaraPesquisa = pd.concat([alvaraPesquisa1985, alvaraPesquisa1992, alvaraPesquisa2000, alvaraPesquisa2001, alvaraPesquisa2002, alvaraPesquisa2005, alvaraPesquisa2008, alvaraPesquisa2009,\n",
    "                            alvaraPesquisa2010, alvaraPesquisa2011, alvaraPesquisa2012, alvaraPesquisa2013, alvaraPesquisa2014, alvaraPesquisa2015, alvaraPesquisa2016, alvaraPesquisa2017, \n",
    "                            alvaraPesquisa2018, alvaraPesquisa2019, alvaraPesquisa2020, alvaraPesquisa2021, alvaraPesquisa2022, alvaraPesquisa2023, alvaraPesquisa2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALVARÃ NÂ° 5473, DE 12 DE AGOSTO DE 1985</td>\n",
       "      <td>Autoriza, pelo prazo de 3 anos, BRENO DE MELO ...</td>\n",
       "      <td>19/08/1985 | 10:56:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALVARÃ NÂº 2.817, DE 30 DE SETEMBRO DE 1992</td>\n",
       "      <td>Autoriza, pelo prazo de 03 (trÃªs) anos, LUIZ A...</td>\n",
       "      <td>07/10/1992 | 15:25:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALVARÃ NÂº 16.025, DEÂ 10 DEÂ AGOSTO DE 2000</td>\n",
       "      <td>AutorizaÂ pelo prazo de 02 (dois) anos, ROMULO ...</td>\n",
       "      <td>15/08/2000 | 15:46:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALVARÃ NÂº 12.091, DE 29 DE MAIO DE 2000</td>\n",
       "      <td>Retifica o AlvarÃ¡ nÂº 7679.</td>\n",
       "      <td>05/06/2000 | 13:08:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALVARÃ NÂº 8.982 DE 26 DE SETEMBRO DE 2001</td>\n",
       "      <td>Outorga o seguinte AlvarÃ¡ de RetificaÃ§Ã£o que e...</td>\n",
       "      <td>28/09/2001 | 14:51:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>ALVARÃ NÂº 44/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Autoriza pelo prazo de 3 anos, AV MINERACAO S....</td>\n",
       "      <td>09/01/2024 | 16:03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>ALVARÃ NÂº 43/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Autoriza pelo prazo de 3 anos, AV MINERACAO S....</td>\n",
       "      <td>09/01/2024 | 16:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>ALVARÃ NÂº 42/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Autoriza pelo prazo de 3 anos, AV MINERACAO S....</td>\n",
       "      <td>09/01/2024 | 15:59:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>ALVARÃ NÂº 41/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Autoriza pelo prazo de 3 anos, AV MINERACAO S....</td>\n",
       "      <td>09/01/2024 | 15:57:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>ALVARÃ NÂº 40/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Autoriza pelo prazo de 3 anos, AV MINERACAO S....</td>\n",
       "      <td>09/01/2024 | 15:55:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94919 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0  \\\n",
       "0        ALVARÃ NÂ° 5473, DE 12 DE AGOSTO DE 1985   \n",
       "0     ALVARÃ NÂº 2.817, DE 30 DE SETEMBRO DE 1992   \n",
       "0      ALVARÃ NÂº 16.025, DEÂ 10 DEÂ AGOSTO DE 2000   \n",
       "1        ALVARÃ NÂº 12.091, DE 29 DE MAIO DE 2000   \n",
       "0      ALVARÃ NÂº 8.982 DE 26 DE SETEMBRO DE 2001   \n",
       "...                                          ...   \n",
       "2535  ALVARÃ NÂº 44/2024, DE 8 DE JANEIRO DE 2024   \n",
       "2536  ALVARÃ NÂº 43/2024, DE 8 DE JANEIRO DE 2024   \n",
       "2537  ALVARÃ NÂº 42/2024, DE 8 DE JANEIRO DE 2024   \n",
       "2538  ALVARÃ NÂº 41/2024, DE 8 DE JANEIRO DE 2024   \n",
       "2539  ALVARÃ NÂº 40/2024, DE 8 DE JANEIRO DE 2024   \n",
       "\n",
       "                                                      1                      2  \n",
       "0     Autoriza, pelo prazo de 3 anos, BRENO DE MELO ...  19/08/1985 | 10:56:06  \n",
       "0     Autoriza, pelo prazo de 03 (trÃªs) anos, LUIZ A...  07/10/1992 | 15:25:35  \n",
       "0     AutorizaÂ pelo prazo de 02 (dois) anos, ROMULO ...  15/08/2000 | 15:46:34  \n",
       "1                            Retifica o AlvarÃ¡ nÂº 7679.  05/06/2000 | 13:08:17  \n",
       "0     Outorga o seguinte AlvarÃ¡ de RetificaÃ§Ã£o que e...  28/09/2001 | 14:51:41  \n",
       "...                                                 ...                    ...  \n",
       "2535  Autoriza pelo prazo de 3 anos, AV MINERACAO S....  09/01/2024 | 16:03:24  \n",
       "2536  Autoriza pelo prazo de 3 anos, AV MINERACAO S....  09/01/2024 | 16:02:06  \n",
       "2537  Autoriza pelo prazo de 3 anos, AV MINERACAO S....  09/01/2024 | 15:59:26  \n",
       "2538  Autoriza pelo prazo de 3 anos, AV MINERACAO S....  09/01/2024 | 15:57:18  \n",
       "2539  Autoriza pelo prazo de 3 anos, AV MINERACAO S....  09/01/2024 | 15:55:53  \n",
       "\n",
       "[94919 rows x 3 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alvaraPesquisa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
