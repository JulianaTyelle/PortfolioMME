{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: chromedriver-autoinstaller in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\juliana.pires\\appdata\\roaming\\python\\python312\\site-packages (from chromedriver-autoinstaller) (24.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\juliana.pires\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juliana.pires\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: bs4 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\juliana.pires\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install chromedriver-autoinstaller\n",
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service()\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://anmlegis.datalegis.net/action/ActionDatalegis.php?acao=apresentacao&cod_modulo=351&cod_menu=8014\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/a[4]').click()\n",
    "#clica em \"Títulos Outorgados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div/div[2]/div[4]/ul/li[4]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"Portarias de concessão de lavra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[1]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2024 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2024 in range (7):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2024 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2024 == last_height2024 :\n",
    "        break   \n",
    "    last_height2024 = new_height2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2024 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2024 = soup2024.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2024 = tabela2024.find_all('strong', {})\n",
    "conteudos2024 = tabela2024.find_all('p')[0:400:2]\n",
    "datasPublicacao2024 = tabela2024.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2024 = []\n",
    "lista_conteudos2024 = []\n",
    "lista_datasPublicacao2024 = []\n",
    "\n",
    "for titulo2024 in titulos2024:\n",
    "  lista_titulos2024.append(titulo2024.get_text().strip())\n",
    "\n",
    "for conteudo2024 in conteudos2024:\n",
    "  lista_conteudos2024.append(conteudo2024.get_text().strip())\n",
    "\n",
    "for dataPublicacao2024 in datasPublicacao2024:\n",
    "  lista_datasPublicacao2024.append(dataPublicacao2024.get_text().strip())\n",
    "\n",
    "df_pcl2024 = pd.DataFrame([lista_titulos2024, lista_conteudos2024, lista_datasPublicacao2024]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[2]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2023 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2023 in range (30):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2023 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2023 == last_height2023 :\n",
    "        break   \n",
    "    last_height2023 = new_height2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2023 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2023 = soup2023.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2023 = tabela2023.find_all('strong', {})\n",
    "conteudos2023 = tabela2023.find_all('p')[0:1210:2]\n",
    "datasPublicacao2023 = tabela2023.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2023 = []\n",
    "lista_conteudos2023 = []\n",
    "lista_datasPublicacao2023 = []\n",
    "\n",
    "for titulo2023 in titulos2023:\n",
    "  lista_titulos2023.append(titulo2023.get_text().strip())\n",
    "\n",
    "for conteudo2023 in conteudos2023:\n",
    "  lista_conteudos2023.append(conteudo2023.get_text().strip())\n",
    "\n",
    "for dataPublicacao2023 in datasPublicacao2023:\n",
    "  lista_datasPublicacao2023.append(dataPublicacao2023.get_text().strip())\n",
    "\n",
    "df_pcl2023 = pd.DataFrame([lista_titulos2023, lista_conteudos2023, lista_datasPublicacao2023]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[3]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2022 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2022 in range (29):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2022 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2022 == last_height2022 :\n",
    "        break   \n",
    "    last_height2022 = new_height2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2022 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2022 = soup2022.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2022 = tabela2022.find_all('strong', {})\n",
    "conteudos2022 = tabela2022.find_all('p')[0:1200:2]\n",
    "datasPublicacao2022 = tabela2022.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2022 = []\n",
    "lista_conteudos2022 = []\n",
    "lista_datasPublicacao2022 = []\n",
    "\n",
    "for titulo2022 in titulos2022:\n",
    "  lista_titulos2022.append(titulo2022.get_text().strip())\n",
    "\n",
    "for conteudo2022 in conteudos2022:\n",
    "  lista_conteudos2022.append(conteudo2022.get_text().strip())\n",
    "\n",
    "for dataPublicacao2022 in datasPublicacao2022:\n",
    "  lista_datasPublicacao2022.append(dataPublicacao2022.get_text().strip())\n",
    "\n",
    "df_pcl2022 = pd.DataFrame([lista_titulos2022, lista_conteudos2022, lista_datasPublicacao2022]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[4]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2021 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2021 in range (28):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2021 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2021 == last_height2021 :\n",
    "        break   \n",
    "    last_height2021 = new_height2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2021 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2021 = soup2021.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2021 = tabela2021.find_all('strong', {})\n",
    "conteudos2021 = tabela2021.find_all('p')[0:1150:2]\n",
    "datasPublicacao2021 = tabela2021.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2021 = []\n",
    "lista_conteudos2021 = []\n",
    "lista_datasPublicacao2021 = []\n",
    "\n",
    "for titulo2021 in titulos2021:\n",
    "  lista_titulos2021.append(titulo2021.get_text().strip())\n",
    "\n",
    "for conteudo2021 in conteudos2021:\n",
    "  lista_conteudos2021.append(conteudo2021.get_text().strip())\n",
    "\n",
    "for dataPublicacao2021 in datasPublicacao2021:\n",
    "  lista_datasPublicacao2021.append(dataPublicacao2021.get_text().strip())\n",
    "\n",
    "df_pcl2021 = pd.DataFrame([lista_titulos2021, lista_conteudos2021, lista_datasPublicacao2021]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[5]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2020 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2020 in range (17):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2020 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2020 == last_height2020 :\n",
    "        break   \n",
    "    last_height2020 = new_height2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2020 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2020 = soup2020.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2020 = tabela2020.find_all('strong', {})\n",
    "conteudos2020 = tabela2020.find_all('p')[0:700:2]\n",
    "datasPublicacao2020 = tabela2020.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2020 = []\n",
    "lista_conteudos2020 = []\n",
    "lista_datasPublicacao2020 = []\n",
    "\n",
    "for titulo2020 in titulos2020:\n",
    "  lista_titulos2020.append(titulo2020.get_text().strip())\n",
    "\n",
    "for conteudo2020 in conteudos2020:\n",
    "  lista_conteudos2020.append(conteudo2020.get_text().strip())\n",
    "\n",
    "for dataPublicacao2020 in datasPublicacao2020:\n",
    "  lista_datasPublicacao2020.append(dataPublicacao2020.get_text().strip())\n",
    "\n",
    "df_pcl2020 = pd.DataFrame([lista_titulos2020, lista_conteudos2020, lista_datasPublicacao2020]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[6]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2019 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2019 in range (3):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2019 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2019 == last_height2019 :\n",
    "        break   \n",
    "    last_height2019 = new_height2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2019 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2019 = soup2019.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2019 = tabela2019.find_all('strong', {})\n",
    "conteudos2019 = tabela2019.find_all('p')[0:90:2]\n",
    "datasPublicacao2019 = tabela2019.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2019 = []\n",
    "lista_conteudos2019 = []\n",
    "lista_datasPublicacao2019 = []\n",
    "\n",
    "for titulo2019 in titulos2019:\n",
    "  lista_titulos2019.append(titulo2019.get_text().strip())\n",
    "\n",
    "for conteudo2019 in conteudos2019:\n",
    "  lista_conteudos2019.append(conteudo2019.get_text().strip())\n",
    "\n",
    "for dataPublicacao2019 in datasPublicacao2019:\n",
    "  lista_datasPublicacao2019.append(dataPublicacao2019.get_text().strip())\n",
    "\n",
    "df_pcl2019 = pd.DataFrame([lista_titulos2019, lista_conteudos2019, lista_datasPublicacao2019]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[7]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2018 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2018 in range (8):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2018 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2018 == last_height2018 :\n",
    "        break   \n",
    "    last_height2018 = new_height2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2018 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2018 = soup2018.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2018 = tabela2018.find_all('strong', {})\n",
    "conteudos2018 = tabela2018.find_all('p')[0:350:2]\n",
    "datasPublicacao2018 = tabela2018.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2018 = []\n",
    "lista_conteudos2018 = []\n",
    "lista_datasPublicacao2018 = []\n",
    "\n",
    "for titulo2018 in titulos2018:\n",
    "  lista_titulos2018.append(titulo2018.get_text().strip())\n",
    "\n",
    "for conteudo2018 in conteudos2018:\n",
    "  lista_conteudos2018.append(conteudo2018.get_text().strip())\n",
    "\n",
    "for dataPublicacao2018 in datasPublicacao2018:\n",
    "  lista_datasPublicacao2018.append(dataPublicacao2018.get_text().strip())\n",
    "\n",
    "df_pcl2018 = pd.DataFrame([lista_titulos2018, lista_conteudos2018, lista_datasPublicacao2018]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[8]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2017 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2017 in range (14):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2017 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2017 == last_height2017 :\n",
    "        break   \n",
    "    last_height2017 = new_height2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2017 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2017 = soup2017.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2017 = tabela2017.find_all('strong', {})\n",
    "conteudos2017 = tabela2017.find_all('p')[0:600:2]\n",
    "datasPublicacao2017 = tabela2017.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2017 = []\n",
    "lista_conteudos2017 = []\n",
    "lista_datasPublicacao2017 = []\n",
    "\n",
    "for titulo2017 in titulos2017:\n",
    "  lista_titulos2017.append(titulo2017.get_text().strip())\n",
    "\n",
    "for conteudo2017 in conteudos2017:\n",
    "  lista_conteudos2017.append(conteudo2017.get_text().strip())\n",
    "\n",
    "for dataPublicacao2017 in datasPublicacao2017:\n",
    "  lista_datasPublicacao2017.append(dataPublicacao2017.get_text().strip())\n",
    "\n",
    "df_pcl2017 = pd.DataFrame([lista_titulos2017, lista_conteudos2017, lista_datasPublicacao2017]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[1]/li[9]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2016 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2016 in range (25):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2016 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2016 == last_height2016 :\n",
    "        break   \n",
    "    last_height2016 = new_height2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2016 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2016 = soup2016.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2016 = tabela2016.find_all('strong', {})\n",
    "conteudos2016 = tabela2016.find_all('p')[0:1000:2]\n",
    "datasPublicacao2016 = tabela2016.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2016 = []\n",
    "lista_conteudos2016 = []\n",
    "lista_datasPublicacao2016 = []\n",
    "\n",
    "for titulo2016 in titulos2016:\n",
    "  lista_titulos2016.append(titulo2016.get_text().strip())\n",
    "\n",
    "for conteudo2016 in conteudos2016:\n",
    "  lista_conteudos2016.append(conteudo2016.get_text().strip())\n",
    "\n",
    "for dataPublicacao2016 in datasPublicacao2016:\n",
    "  lista_datasPublicacao2016.append(dataPublicacao2016.get_text().strip())\n",
    "\n",
    "df_pcl2016 = pd.DataFrame([lista_titulos2016, lista_conteudos2016, lista_datasPublicacao2016]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[1]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2015 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2015 in range (27):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2015 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2015 == last_height2015 :\n",
    "        break   \n",
    "    last_height2015 = new_height2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2015 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2015 = soup2015.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2015 = tabela2015.find_all('strong', {})\n",
    "conteudos2015 = tabela2015.find_all('p')[0:1100:2]\n",
    "datasPublicacao2015 = tabela2015.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2015 = []\n",
    "lista_conteudos2015 = []\n",
    "lista_datasPublicacao2015 = []\n",
    "\n",
    "for titulo2015 in titulos2015:\n",
    "  lista_titulos2015.append(titulo2015.get_text().strip())\n",
    "\n",
    "for conteudo2015 in conteudos2015:\n",
    "  lista_conteudos2015.append(conteudo2015.get_text().strip())\n",
    "\n",
    "for dataPublicacao2015 in datasPublicacao2015:\n",
    "  lista_datasPublicacao2015.append(dataPublicacao2015.get_text().strip())\n",
    "\n",
    "df_pcl2015 = pd.DataFrame([lista_titulos2015, lista_conteudos2015, lista_datasPublicacao2015]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[2]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2014 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2014 in range (15):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2014 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2014 == last_height2014 :\n",
    "        break   \n",
    "    last_height2014 = new_height2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2014 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2014 = soup2014.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2014 = tabela2014.find_all('strong', {})\n",
    "conteudos2014 = tabela2014.find_all('p')[0:650:2]\n",
    "datasPublicacao2014 = tabela2014.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2014 = []\n",
    "lista_conteudos2014 = []\n",
    "lista_datasPublicacao2014 = []\n",
    "\n",
    "for titulo2014 in titulos2014:\n",
    "  lista_titulos2014.append(titulo2014.get_text().strip())\n",
    "\n",
    "for conteudo2014 in conteudos2014:\n",
    "  lista_conteudos2014.append(conteudo2014.get_text().strip())\n",
    "\n",
    "for dataPublicacao2014 in datasPublicacao2014:\n",
    "  lista_datasPublicacao2014.append(dataPublicacao2014.get_text().strip())\n",
    "\n",
    "df_pcl2014 = pd.DataFrame([lista_titulos2014, lista_conteudos2014, lista_datasPublicacao2014]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[3]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2013 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2013 in range (9):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2013 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2013 == last_height2013 :\n",
    "        break   \n",
    "    last_height2013 = new_height2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2013 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2013 = soup2013.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2013 = tabela2013.find_all('strong', {})\n",
    "conteudos2013 = tabela2013.find_all('p')[0:200:2]\n",
    "datasPublicacao2013 = tabela2013.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2013 = []\n",
    "lista_conteudos2013 = []\n",
    "lista_datasPublicacao2013 = []\n",
    "\n",
    "for titulo2013 in titulos2013:\n",
    "  lista_titulos2013.append(titulo2013.get_text().strip())\n",
    "\n",
    "for conteudo2013 in conteudos2013:\n",
    "  lista_conteudos2013.append(conteudo2013.get_text().strip())\n",
    "\n",
    "for dataPublicacao2013 in datasPublicacao2013:\n",
    "  lista_datasPublicacao2013.append(dataPublicacao2013.get_text().strip())\n",
    "\n",
    "df_pcl2013 = pd.DataFrame([lista_titulos2013, lista_conteudos2013, lista_datasPublicacao2013]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[4]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2012\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2012 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2012 in range (19):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2012 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2012 == last_height2012 :\n",
    "        break   \n",
    "    last_height2012 = new_height2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2012 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2012 = soup2012.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2012 = tabela2012.find_all('strong', {})\n",
    "conteudos2012 = tabela2012.find_all('p')[0:800:2]\n",
    "datasPublicacao2012 = tabela2012.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2012 = []\n",
    "lista_conteudos2012 = []\n",
    "lista_datasPublicacao2012 = []\n",
    "\n",
    "for titulo2012 in titulos2012:\n",
    "  lista_titulos2012.append(titulo2012.get_text().strip())\n",
    "\n",
    "for conteudo2012 in conteudos2012:\n",
    "  lista_conteudos2012.append(conteudo2012.get_text().strip())\n",
    "\n",
    "for dataPublicacao2012 in datasPublicacao2012:\n",
    "  lista_datasPublicacao2012.append(dataPublicacao2012.get_text().strip())\n",
    "\n",
    "df_pcl2012 = pd.DataFrame([lista_titulos2012, lista_conteudos2012, lista_datasPublicacao2012]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[5]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2011 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2011 in range (11):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2011 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2011 == last_height2011 :\n",
    "        break   \n",
    "    last_height2011 = new_height2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2011 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2011 = soup2011.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2011 = tabela2011.find_all('strong', {})\n",
    "conteudos2011 = tabela2011.find_all('p')[0:450:2]\n",
    "datasPublicacao2011 = tabela2011.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2011 = []\n",
    "lista_conteudos2011 = []\n",
    "lista_datasPublicacao2011 = []\n",
    "\n",
    "for titulo2011 in titulos2011:\n",
    "  lista_titulos2011.append(titulo2011.get_text().strip())\n",
    "\n",
    "for conteudo2011 in conteudos2011:\n",
    "  lista_conteudos2011.append(conteudo2011.get_text().strip())\n",
    "\n",
    "for dataPublicacao2011 in datasPublicacao2011:\n",
    "  lista_datasPublicacao2011.append(dataPublicacao2011.get_text().strip())\n",
    "\n",
    "df_pcl2011 = pd.DataFrame([lista_titulos2011, lista_conteudos2011, lista_datasPublicacao2011]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[6]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2010 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2010 in range (12):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2010 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2010 == last_height2010 :\n",
    "        break   \n",
    "    last_height2010 = new_height2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2010 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2010 = soup2010.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2010 = tabela2010.find_all('strong', {})\n",
    "conteudos2010 = tabela2010.find_all('p')[0:500:2]\n",
    "datasPublicacao2010 = tabela2010.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2010 = []\n",
    "lista_conteudos2010 = []\n",
    "lista_datasPublicacao2010 = []\n",
    "\n",
    "for titulo2010 in titulos2010:\n",
    "  lista_titulos2010.append(titulo2010.get_text().strip())\n",
    "\n",
    "for conteudo2010 in conteudos2010:\n",
    "  lista_conteudos2010.append(conteudo2010.get_text().strip())\n",
    "\n",
    "for dataPublicacao2010 in datasPublicacao2010:\n",
    "  lista_datasPublicacao2010.append(dataPublicacao2010.get_text().strip())\n",
    "\n",
    "df_pcl2010 = pd.DataFrame([lista_titulos2010, lista_conteudos2010, lista_datasPublicacao2010]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[7]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2009\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2009 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2009 in range (22):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2009 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2009 == last_height2009 :\n",
    "        break   \n",
    "    last_height2009 = new_height2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2009 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2009 = soup2009.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2009 = tabela2009.find_all('strong', {})\n",
    "conteudos2009 = tabela2009.find_all('p')[0:900:2]\n",
    "datasPublicacao2009 = tabela2009.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2009 = []\n",
    "lista_conteudos2009 = []\n",
    "lista_datasPublicacao2009 = []\n",
    "\n",
    "for titulo2009 in titulos2009:\n",
    "  lista_titulos2009.append(titulo2009.get_text().strip())\n",
    "\n",
    "for conteudo2009 in conteudos2009:\n",
    "  lista_conteudos2009.append(conteudo2009.get_text().strip())\n",
    "\n",
    "for dataPublicacao2009 in datasPublicacao2009:\n",
    "  lista_datasPublicacao2009.append(dataPublicacao2009.get_text().strip())\n",
    "\n",
    "df_pcl2009 = pd.DataFrame([lista_titulos2009, lista_conteudos2009, lista_datasPublicacao2009]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[8]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2008\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2008 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2008 in range (17):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2008 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2008 == last_height2008 :\n",
    "        break   \n",
    "    last_height2008 = new_height2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2008 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2008 = soup2008.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2008 = tabela2008.find_all('strong', {})\n",
    "conteudos2008 = tabela2008.find_all('p')[0:700:2]\n",
    "datasPublicacao2008 = tabela2008.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2008 = []\n",
    "lista_conteudos2008 = []\n",
    "lista_datasPublicacao2008 = []\n",
    "\n",
    "for titulo2008 in titulos2008:\n",
    "  lista_titulos2008.append(titulo2008.get_text().strip())\n",
    "\n",
    "for conteudo2008 in conteudos2008:\n",
    "  lista_conteudos2008.append(conteudo2008.get_text().strip())\n",
    "\n",
    "for dataPublicacao2008 in datasPublicacao2008:\n",
    "  lista_datasPublicacao2008.append(dataPublicacao2008.get_text().strip())\n",
    "\n",
    "df_pcl2008 = pd.DataFrame([lista_titulos2008, lista_conteudos2008, lista_datasPublicacao2008]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[2]/li[9]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2007 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2007 in range (19):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2007 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2007 == last_height2007 :\n",
    "        break   \n",
    "    last_height2007 = new_height2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2007 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2007 = soup2007.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2007 = tabela2007.find_all('strong', {})\n",
    "conteudos2007 = tabela2007.find_all('p')[0:800:2]\n",
    "datasPublicacao2007 = tabela2007.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2007 = []\n",
    "lista_conteudos2007 = []\n",
    "lista_datasPublicacao2007 = []\n",
    "\n",
    "for titulo2007 in titulos2007:\n",
    "  lista_titulos2007.append(titulo2007.get_text().strip())\n",
    "\n",
    "for conteudo2007 in conteudos2007:\n",
    "  lista_conteudos2007.append(conteudo2007.get_text().strip())\n",
    "\n",
    "for dataPublicacao2007 in datasPublicacao2007:\n",
    "  lista_datasPublicacao2007.append(dataPublicacao2007.get_text().strip())\n",
    "\n",
    "df_pcl2007 = pd.DataFrame([lista_titulos2007, lista_conteudos2007, lista_datasPublicacao2007]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[1]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2006 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2006 in range (25):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2006 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2006 == last_height2006 :\n",
    "        break   \n",
    "    last_height2006 = new_height2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2006 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2006 = soup2006.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2006 = tabela2006.find_all('strong', {})\n",
    "conteudos2006 = tabela2006.find_all('p')[0:1000:2]\n",
    "datasPublicacao2006 = tabela2006.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2006 = []\n",
    "lista_conteudos2006 = []\n",
    "lista_datasPublicacao2006 = []\n",
    "\n",
    "for titulo2006 in titulos2006:\n",
    "  lista_titulos2006.append(titulo2006.get_text().strip())\n",
    "\n",
    "for conteudo2006 in conteudos2006:\n",
    "  lista_conteudos2006.append(conteudo2006.get_text().strip())\n",
    "\n",
    "for dataPublicacao2006 in datasPublicacao2006:\n",
    "  lista_datasPublicacao2006.append(dataPublicacao2006.get_text().strip())\n",
    "\n",
    "df_pcl2006 = pd.DataFrame([lista_titulos2006, lista_conteudos2006, lista_datasPublicacao2006]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[2]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height2005 = driver.execute_script(\"return document.body.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vez2005 in range (20):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    new_height2005 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height2005 == last_height2005 :\n",
    "        break   \n",
    "    last_height2005 = new_height2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2005 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2005 = soup2005.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2005 = tabela2005.find_all('strong', {})\n",
    "conteudos2005 = tabela2005.find_all('p')[0:830:2]\n",
    "datasPublicacao2005 = tabela2005.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2005 = []\n",
    "lista_conteudos2005 = []\n",
    "lista_datasPublicacao2005 = []\n",
    "\n",
    "for titulo2005 in titulos2005:\n",
    "  lista_titulos2005.append(titulo2005.get_text().strip())\n",
    "\n",
    "for conteudo2005 in conteudos2005:\n",
    "  lista_conteudos2005.append(conteudo2005.get_text().strip())\n",
    "\n",
    "for dataPublicacao2005 in datasPublicacao2005:\n",
    "  lista_datasPublicacao2005.append(dataPublicacao2005.get_text().strip())\n",
    "\n",
    "df_pcl2005 = pd.DataFrame([lista_titulos2005, lista_conteudos2005, lista_datasPublicacao2005]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[3]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2004 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2004 = soup2004.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2004 = tabela2004.find_all('strong', {})\n",
    "conteudos2004 = tabela2004.find_all('p')[0:20:2]\n",
    "datasPublicacao2004 = tabela2004.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2004 = []\n",
    "lista_conteudos2004 = []\n",
    "lista_datasPublicacao2004 = []\n",
    "\n",
    "for titulo2004 in titulos2004:\n",
    "  lista_titulos2004.append(titulo2004.get_text().strip())\n",
    "\n",
    "for conteudo2004 in conteudos2004:\n",
    "  lista_conteudos2004.append(conteudo2004.get_text().strip())\n",
    "\n",
    "for dataPublicacao2004 in datasPublicacao2004:\n",
    "  lista_datasPublicacao2004.append(dataPublicacao2004.get_text().strip())\n",
    "\n",
    "df_pcl2004 = pd.DataFrame([lista_titulos2004, lista_conteudos2004, lista_datasPublicacao2004]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[4]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"2002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2002 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2002 = soup2002.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos2002 = tabela2002.find_all('strong', {})\n",
    "conteudos2002 = tabela2002.find_all('p')[0:20:2]\n",
    "datasPublicacao2002 = tabela2002.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos2002 = []\n",
    "lista_conteudos2002 = []\n",
    "lista_datasPublicacao2002 = []\n",
    "\n",
    "for titulo2002 in titulos2002:\n",
    "  lista_titulos2002.append(titulo2002.get_text().strip())\n",
    "\n",
    "for conteudo2002 in conteudos2002:\n",
    "  lista_conteudos2002.append(conteudo2002.get_text().strip())\n",
    "\n",
    "for dataPublicacao2002 in datasPublicacao2002:\n",
    "  lista_datasPublicacao2002.append(dataPublicacao2002.get_text().strip())\n",
    "\n",
    "df_pcl2002 = pd.DataFrame([lista_titulos2002, lista_conteudos2002, lista_datasPublicacao2002]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[5]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"1999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1999 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1999 = soup1999.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos1999 = tabela1999.find_all('strong', {})\n",
    "conteudos1999 = tabela1999.find_all('p')[0:4:2]\n",
    "datasPublicacao1999 = tabela1999.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos1999 = []\n",
    "lista_conteudos1999 = []\n",
    "lista_datasPublicacao1999 = []\n",
    "\n",
    "for titulo1999 in titulos1999:\n",
    "  lista_titulos1999.append(titulo1999.get_text().strip())\n",
    "\n",
    "for conteudo1999 in conteudos1999:\n",
    "  lista_conteudos1999.append(conteudo1999.get_text().strip())\n",
    "\n",
    "for dataPublicacao1999 in datasPublicacao1999:\n",
    "  lista_datasPublicacao1999.append(dataPublicacao1999.get_text().strip())\n",
    "\n",
    "df_pcl1999 = pd.DataFrame([lista_titulos1999, lista_conteudos1999, lista_datasPublicacao1999]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[6]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"1998\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1998 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1998 = soup1998.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos1998 = tabela1998.find_all('strong', {})\n",
    "conteudos1998 = tabela1998.find_all('p')[0:4:2]\n",
    "datasPublicacao1998 = tabela1998.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos1998 = []\n",
    "lista_conteudos1998 = []\n",
    "lista_datasPublicacao1998 = []\n",
    "\n",
    "for titulo1998 in titulos1998:\n",
    "  lista_titulos1998.append(titulo1998.get_text().strip())\n",
    "\n",
    "for conteudo1998 in conteudos1998:\n",
    "  lista_conteudos1998.append(conteudo1998.get_text().strip())\n",
    "\n",
    "for dataPublicacao1998 in datasPublicacao1998:\n",
    "  lista_datasPublicacao1998.append(dataPublicacao1998.get_text().strip())\n",
    "\n",
    "df_pcl1998 = pd.DataFrame([lista_titulos1998, lista_conteudos1998, lista_datasPublicacao1998]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"column-2\"]/div[1]/ul[3]/li[7]/a').click()\n",
    "time.sleep(5)\n",
    "#clica em \"1982\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1982 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1982 = soup1982.find('div', {'class': {'col-lg-11 col-md-11 col-sm-12'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos1982 = tabela1982.find_all('strong', {})\n",
    "conteudos1982 = tabela1982.find_all('p')[0:4:2]\n",
    "datasPublicacao1982 = tabela1982.find_all('p', {'class': 'data-hora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_titulos1982 = []\n",
    "lista_conteudos1982 = []\n",
    "lista_datasPublicacao1982 = []\n",
    "\n",
    "for titulo1982 in titulos1982:\n",
    "  lista_titulos1982.append(titulo1982.get_text().strip())\n",
    "\n",
    "for conteudo1982 in conteudos1982:\n",
    "  lista_conteudos1982.append(conteudo1982.get_text().strip())\n",
    "\n",
    "for dataPublicacao1982 in datasPublicacao1982:\n",
    "  lista_datasPublicacao1982.append(dataPublicacao1982.get_text().strip())\n",
    "\n",
    "df_pcl1982 = pd.DataFrame([lista_titulos1982, lista_conteudos1982, lista_datasPublicacao1982]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "portariaConcessaoLavra = pd.concat([df_pcl1982, df_pcl1998, df_pcl1999, df_pcl2002, df_pcl2004, df_pcl2005, df_pcl2006, df_pcl2007, df_pcl2008, df_pcl2009, df_pcl2010, df_pcl2011\n",
    "                                    , df_pcl2012, df_pcl2013, df_pcl2014, df_pcl2015, df_pcl2016, df_pcl2017, df_pcl2018, df_pcl2019, df_pcl2020, df_pcl2021, df_pcl2022, df_pcl2023\n",
    "                                    , df_pcl2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PORTARIA Nº 1.417, DE 05 DE OUTUBRO DE 1982</td>\n",
       "      <td>Outorga à MARSAL - Marmore Salviano S/A conces...</td>\n",
       "      <td>11/10/1982 | 16:04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PORTARIA Nº 9, DE 9 DE JANEIRO DE 1998</td>\n",
       "      <td>Outorga à COMPANHIA DE CIMENTO GOIÁS, concessã...</td>\n",
       "      <td>14/01/1998 | 13:50:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PORTARIA Nº 450, DE 17 DE NOVEMBRO DE 1999</td>\n",
       "      <td>Outorga à ENGEXPLO - DESMONTE A EXPLO- SIVOS L...</td>\n",
       "      <td>18/11/1999 | 16:15:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MME - Portaria 546/2002</td>\n",
       "      <td>Outorga à MINERAÇÃO DE AREIA PARAÍBA DO SUL LT...</td>\n",
       "      <td>07/11/2002 |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MME - Portaria 287/2002</td>\n",
       "      <td>Outorga à GEO-LOG DO BRASIL LTDA, concessão pa...</td>\n",
       "      <td>19/07/2002 |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>PORTARIA ANM N° 3/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Outorga ao (à) titular NAVEGACAO SAO MARTINHO ...</td>\n",
       "      <td>09/01/2024 | 12:08:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>PORTARIA ANM N° 2/2024, DE 8 DE JANEIRO DE 2024</td>\n",
       "      <td>Outorga ao (à) titular ITAVEL SERVIÇOS RODOVIÁ...</td>\n",
       "      <td>09/01/2024 | 12:07:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>PORTARIA ANM N° 1/2024, DE 4 DE JANEIRO DE 2024</td>\n",
       "      <td>Outorga ao (à) titular PIAUI NIQUEL METAIS S/A...</td>\n",
       "      <td>05/01/2024 | 15:13:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>PORTARIA ANM N° 601/2023, DE 29 DE DEZEMBRO DE...</td>\n",
       "      <td>Outorga ao (à) titular PEDREIRA COSME E DAMIAO...</td>\n",
       "      <td>03/01/2024 | 14:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>PORTARIA ANM N° 600/2023, DE 29 DE DEZEMBRO DE...</td>\n",
       "      <td>Outorga ao (à) titular GLOBUS MINERACAO COMERC...</td>\n",
       "      <td>03/01/2024 | 14:47:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6976 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0          PORTARIA Nº 1.417, DE 05 DE OUTUBRO DE 1982   \n",
       "0               PORTARIA Nº 9, DE 9 DE JANEIRO DE 1998   \n",
       "0           PORTARIA Nº 450, DE 17 DE NOVEMBRO DE 1999   \n",
       "0                              MME - Portaria 546/2002   \n",
       "1                              MME - Portaria 287/2002   \n",
       "..                                                 ...   \n",
       "135    PORTARIA ANM N° 3/2024, DE 8 DE JANEIRO DE 2024   \n",
       "136    PORTARIA ANM N° 2/2024, DE 8 DE JANEIRO DE 2024   \n",
       "137    PORTARIA ANM N° 1/2024, DE 4 DE JANEIRO DE 2024   \n",
       "138  PORTARIA ANM N° 601/2023, DE 29 DE DEZEMBRO DE...   \n",
       "139  PORTARIA ANM N° 600/2023, DE 29 DE DEZEMBRO DE...   \n",
       "\n",
       "                                                     1                      2  \n",
       "0    Outorga à MARSAL - Marmore Salviano S/A conces...  11/10/1982 | 16:04:48  \n",
       "0    Outorga à COMPANHIA DE CIMENTO GOIÁS, concessã...  14/01/1998 | 13:50:44  \n",
       "0    Outorga à ENGEXPLO - DESMONTE A EXPLO- SIVOS L...  18/11/1999 | 16:15:49  \n",
       "0    Outorga à MINERAÇÃO DE AREIA PARAÍBA DO SUL LT...           07/11/2002 |  \n",
       "1    Outorga à GEO-LOG DO BRASIL LTDA, concessão pa...           19/07/2002 |  \n",
       "..                                                 ...                    ...  \n",
       "135  Outorga ao (à) titular NAVEGACAO SAO MARTINHO ...  09/01/2024 | 12:08:35  \n",
       "136  Outorga ao (à) titular ITAVEL SERVIÇOS RODOVIÁ...  09/01/2024 | 12:07:18  \n",
       "137  Outorga ao (à) titular PIAUI NIQUEL METAIS S/A...  05/01/2024 | 15:13:57  \n",
       "138  Outorga ao (à) titular PEDREIRA COSME E DAMIAO...  03/01/2024 | 14:35:00  \n",
       "139  Outorga ao (à) titular GLOBUS MINERACAO COMERC...  03/01/2024 | 14:47:47  \n",
       "\n",
       "[6976 rows x 3 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portariaConcessaoLavra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
